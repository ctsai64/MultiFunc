{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:3\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer_Encoder(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_channel_size, \n",
    "                 hidden_channel_size, \n",
    "                 sequence_length, \n",
    "                 num_heads = 4,\n",
    "                 drop_out = 0.1\n",
    "                ):\n",
    "        super(Transformer_Encoder, self).__init__()\n",
    "        \n",
    "        self.cov1d = nn.Conv1d(input_channel_size, hidden_channel_size, 2, stride=2, padding=0, padding_mode='zeros')\n",
    "        # Multihead attention layer\n",
    "        self.attention = nn.MultiheadAttention(embed_dim=sequence_length, num_heads=num_heads,batch_first=True)\n",
    "        \n",
    "\n",
    "        # Feedforward layer\n",
    "        self.feedforward = nn.Sequential(\n",
    "            nn.Linear(sequence_length, sequence_length),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(sequence_length, sequence_length)\n",
    "        )\n",
    "\n",
    "        # Layer normalization\n",
    "        self.layer_norm1 = nn.LayerNorm(sequence_length)\n",
    "        self.layer_norm2 = nn.LayerNorm(sequence_length)\n",
    "\n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(drop_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Multihead attention\n",
    "        x = self.cov1d(x)\n",
    "\n",
    "        attn_output, _ = self.attention(x, x, x)\n",
    "\n",
    "\n",
    "        # Add and normalize\n",
    "        x = self.layer_norm1(x + self.dropout(attn_output))\n",
    "\n",
    "        # Feedforward\n",
    "        ff_output = self.feedforward(x)\n",
    "\n",
    "        # Add and normalize\n",
    "        x = self.layer_norm2(x + self.dropout(ff_output))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer_Decoder(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_channel_size, \n",
    "                 hidden_channel_size, \n",
    "                 sequence_length,\n",
    "                 num_heads=4,\n",
    "                 drop_out = 0.1\n",
    "                ):\n",
    "        super(Transformer_Decoder, self).__init__()\n",
    "        \n",
    "        self.covtrans1d = nn.ConvTranspose1d(input_channel_size, hidden_channel_size, 2, stride=2, padding=0, padding_mode='zeros')\n",
    "        # Multihead attention layer\n",
    "        self.attention_1 = nn.MultiheadAttention(embed_dim=sequence_length, num_heads=num_heads,batch_first=True)\n",
    "#        self.attention_2 = nn.MultiheadAttention(embed_dim=sequence_length, num_heads=num_heads,batch_first=True)\n",
    "        \n",
    "\n",
    "        # Feedforward layer\n",
    "        self.feedforward = nn.Sequential(\n",
    "            nn.Linear(sequence_length, sequence_length),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(sequence_length, sequence_length)\n",
    "        )\n",
    "\n",
    "        # Layer normalization\n",
    "        self.layer_norm1 = nn.LayerNorm(sequence_length)\n",
    "#        self.layer_norm2 = nn.LayerNorm(sequence_length)\n",
    "        self.layer_norm3 = nn.LayerNorm(sequence_length)\n",
    "\n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(drop_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Multihead attention\n",
    "        \n",
    "        attn_output, _ = self.attention_1(x, x, x)\n",
    "\n",
    "        # Add and normalize\n",
    "        x = self.layer_norm1(x + self.dropout(attn_output))\n",
    "        \n",
    "        # add multihead-attention to result from encoder\n",
    "#        attn_output, _ = self.attention_2(x,encoder_out,encoder_out)\n",
    "        \n",
    "        # Add and normalize\n",
    "#        x = self.layer_norm2(x + self.dropout(attn_output))\n",
    "        \n",
    "        # Feedforward\n",
    "        ff_output = self.feedforward(x)\n",
    "        \n",
    "        # Add and normalize\n",
    "        x = self.layer_norm3(x + self.dropout(ff_output))\n",
    "        \n",
    "        x = self.covtrans1d(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, \n",
    "                 sequence_length=96, \n",
    "                 input_channel=2, \n",
    "                 embedding_size = 16, \n",
    "                 cov1d_size=128,\n",
    "                 num_heads = 4,\n",
    "                 drop_out = 0.1\n",
    "                ):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.cov1d = nn.Conv1d(input_channel, cov1d_size, 3, stride=1, padding=1, padding_mode='zeros')\n",
    "        self.cov1d_1 = nn.Conv1d(cov1d_size, 1, 3, stride=1, padding=1, padding_mode='zeros')\n",
    "        \n",
    "        sequence_length = int(sequence_length/2)\n",
    "        \n",
    "        \n",
    "        self.transformer_1 = Transformer_Encoder(cov1d_size, \n",
    "                                                 cov1d_size, \n",
    "                                                 sequence_length,\n",
    "                                                 num_heads,\n",
    "                                                 drop_out)\n",
    "        \n",
    "        sequence_length = int(sequence_length/2)\n",
    "        \n",
    "        \n",
    "        self.transformer_2 = Transformer_Encoder(cov1d_size, \n",
    "                                                 cov1d_size, \n",
    "                                                 sequence_length,\n",
    "                                                 num_heads,\n",
    "                                                 drop_out)\n",
    "        sequence_length = int(sequence_length/2)\n",
    "        \n",
    "        \n",
    "        self.transformer_3 = Transformer_Encoder(cov1d_size, \n",
    "                                                 cov1d_size, \n",
    "                                                 sequence_length,\n",
    "                                                 num_heads,\n",
    "                                                 drop_out)\n",
    "        \n",
    "        self.relu_1 = nn.ReLU()\n",
    "\n",
    "\n",
    "        self.dense = nn.Linear(sequence_length, embedding_size)\n",
    "\n",
    "    #        self.sd = nn.Linear(32,8)\n",
    "    #        self.logspike = nn.Linear(32,8)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        out = self.cov1d(x)\n",
    "        \n",
    "        enc_trans_1 = self.transformer_1(out)\n",
    "        \n",
    "        enc_trans_2 = self.transformer_2(enc_trans_1)\n",
    "        \n",
    "        enc_trans_3 = self.transformer_3(enc_trans_2)\n",
    "        \n",
    "        out = self.cov1d_1(enc_trans_3)\n",
    "        \n",
    "        out = out.squeeze(1)\n",
    "\n",
    "        out = self.dense(out)\n",
    "        \n",
    "        out = self.relu_1(out)\n",
    "        \n",
    "\n",
    "\n",
    "        return out, enc_trans_1, enc_trans_2, enc_trans_3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, \n",
    "                 sequence_length=12, \n",
    "                 input_channel=2, \n",
    "                 embedding_size = 16, \n",
    "                 cov1d_size=128,\n",
    "                 num_heads = 4,\n",
    "                 drop_out = 0.1\n",
    "                ):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.cov1d = nn.Conv1d(1, cov1d_size, 3, stride=1, padding=1, padding_mode='zeros')\n",
    "        self.cov1d_1 = nn.Conv1d(cov1d_size, input_channel, 3, stride=1, padding=1, padding_mode='zeros')\n",
    "        self.dense = nn.Linear(embedding_size, sequence_length)\n",
    "        \n",
    "        \n",
    "        self.transformer_1 = Transformer_Decoder(cov1d_size, \n",
    "                                                 cov1d_size, \n",
    "                                                 sequence_length,\n",
    "                                                 num_heads,\n",
    "                                                 drop_out)\n",
    "        \n",
    "        sequence_length = int(sequence_length*2)\n",
    "        \n",
    "        \n",
    "        self.transformer_2 = Transformer_Decoder(cov1d_size, \n",
    "                                                 cov1d_size, \n",
    "                                                 sequence_length,\n",
    "                                                 num_heads,\n",
    "                                                 drop_out)\n",
    "        sequence_length = int(sequence_length*2)\n",
    "        \n",
    "        \n",
    "        self.transformer_3 = Transformer_Decoder(cov1d_size, \n",
    "                                                 cov1d_size, \n",
    "                                                 sequence_length,\n",
    "                                                 num_heads,\n",
    "                                                 drop_out)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "#        x = x.transpose(1, 2)\n",
    "        out = self.dense(x)\n",
    "    \n",
    "        out = out.unsqueeze(1)\n",
    "\n",
    "        out = self.cov1d(out)\n",
    "        \n",
    "        out = self.transformer_1(out)\n",
    "        \n",
    "        out = self.transformer_2(out)\n",
    "        \n",
    "        out = self.transformer_3(out)\n",
    "        \n",
    "        out = self.cov1d_1(out)\n",
    "        \n",
    "\n",
    "\n",
    "        return out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    ''' This the VAE, which takes a encoder and decoder.\n",
    "\n",
    "    '''\n",
    "\n",
    "    def __init__(self, \n",
    "                 enc, \n",
    "                 dec, \n",
    "                 embedding_size = 16, \n",
    "                 num_vae=1,\n",
    "                 fix_channel = False,\n",
    "                 set_topK = True,\n",
    "                 topk = 1,\n",
    "                 channel_list = [0,1,2,3]\n",
    "                ):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        self.enc = enc\n",
    "        self.dec = dec\n",
    "        self.num_vae = num_vae\n",
    "        self.mn  = nn.Linear(embedding_size, embedding_size)\n",
    "        self.var = nn.Linear(embedding_size,embedding_size)\n",
    "        self.relu_1 = nn.ReLU()\n",
    "        self.fix_channel = fix_channel\n",
    "        self.channel_list = channel_list\n",
    "        self.set_topK = set_topK\n",
    "        self.topk = topk\n",
    "        if self.num_vae == 2:\n",
    "            self.mn_after = nn.Linear(embedding_size,embedding_size)\n",
    "            self.var_after = nn.Linear(embedding_size,embedding_size)\n",
    "            self.relu_2 = nn.ReLU()\n",
    "#        self.embedding_layer = nn.Linear(embedding_size,embedding_size)\n",
    "        \n",
    "        if self.fix_channel:\n",
    "            to_zero = [e for e in range(embedding_size) if e not in self.channel_list]\n",
    "            self.zero_index = torch.tensor(to_zero,dtype = torch.int)\n",
    "                   \n",
    "        \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        \n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        \n",
    "        return mu + eps*std\n",
    "    \n",
    "    \n",
    "    def specify_channel(self, embed_):\n",
    "        \n",
    "        embed_co = torch.clone(embed_)\n",
    "        embed_co[:,self.zero_index]=0\n",
    "        \n",
    "        return embed_co\n",
    "    \n",
    "    def set_K(self,embed_):\n",
    "        \n",
    "        embed_co = torch.clone(embed_)\n",
    "        for i in range(embed_.shape[0]):\n",
    "            to_zero = [e for e in range(embed_.shape[1]) if e not in torch.topk(embed_co[i],self.topk)[1]]\n",
    "            zero_index = torch.tensor(to_zero,dtype = torch.int)\n",
    "            embed_co[i,zero_index] = 0\n",
    "        \n",
    "        return embed_co\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "    def forward(self, \n",
    "                x,\n",
    "               ):\n",
    "        # encode\n",
    "        encoder_out,enc_trans_1,enc_trans_2,enc_trans_3 = self.enc(x)\n",
    "        \n",
    "        # variational layer\n",
    "        mn_ = self.mn(encoder_out)\n",
    "        var_ = self.var(encoder_out)\n",
    "        h1 = self.reparameterize(mn_,var_)\n",
    "#        pre_embedding = self.embedding_layer(h1)\n",
    "        embedding = self.relu_1(h1)\n",
    "        \n",
    "        \n",
    "        # another VAE layer\n",
    "        if self.num_vae == 2:\n",
    "        # sample from the distribution having latent parameters z_mu, z_var\n",
    "        # reparameterize\n",
    "            mn_after = self.mn_after(embedding)\n",
    "            var_after = self.var_after(embedding)\n",
    "            h2 = self.reparameterize(mn_after,var_after)\n",
    "            h2 = self.relu_2(h2)\n",
    "            if self.fix_channel:\n",
    "                h2 = self.specify_channel(h2)\n",
    "            elif self.set_topK:\n",
    "                h2 = self.set_K(h2)\n",
    "            # decode\n",
    "            predicted = self.dec(h2)\n",
    "            \n",
    "            return predicted, embedding, mn_,var_, mn_after,var_after, h2\n",
    "        \n",
    "        if self.fix_channel:\n",
    "            \n",
    "            embedding = self.specify_channel(embedding)\n",
    "            \n",
    "        elif self.set_topK:\n",
    "            embedding = self.set_K(embedding)\n",
    "            \n",
    "        \n",
    "        predicted = self.dec(embedding)\n",
    "        \n",
    "        return predicted, embedding, mn_, var_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_tensor(min=0, max=1, size=(1)):\n",
    "    out = (max - min) * torch.rand(size) + min\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Polynomial_func:\n",
    "    def __init__(self, x, range=[-1,1], degree = 3, size=(1,1), sample_size=100, device=\"cuda\"):\n",
    "        self.x = x\n",
    "        self.range = range\n",
    "        self.degree = degree\n",
    "        self.size = size\n",
    "        self.sample_size = sample_size\n",
    "        self.device = device\n",
    "\n",
    "    def generate(self):\n",
    "        hold = []\n",
    "        for n in range(self.degree + 1):\n",
    "            p = rand_tensor(\n",
    "                min=self.range[0],\n",
    "                max=self.range[1],\n",
    "                size=(self.sample_size, self.size[0], self.size[1]),\n",
    "            )\n",
    "            hold.append(p)\n",
    "        params = torch.stack(hold)\n",
    "        params = torch.atleast_2d(params)\n",
    "        params = torch.transpose(params, 0, 1)\n",
    "        params = torch.transpose(params, 1, 2)\n",
    "        params = params.to(self.device)\n",
    "\n",
    "        x = (\n",
    "            torch.cat(params.shape[0] * [self.x])\n",
    "            .reshape(params.shape[0], -1)\n",
    "            .to(self.device)\n",
    "        )\n",
    "        x = torch.transpose(x, 0, 1).to(self.device)\n",
    "        y = torch.zeros_like(x)\n",
    "\n",
    "        for d in range(self.degree+1):\n",
    "            coeffs = params[:,0,d,0]\n",
    "            y += coeffs*(x**d)\n",
    "        out = torch.zeros(\n",
    "                (params.shape[0], self.x.shape[0],\n",
    "                self.size[0], self.size[1])\n",
    "            ).to(self.device)            \n",
    "        out[:,:,0,0] = torch.transpose(y,0,1)\n",
    "        return (torch.sum(out,dim=3), out), params\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_function(params, x, device):\n",
    "    x = x.to(device)\n",
    "    if params.size(1) > 1:\n",
    "        a = params[:, 0].type(torch.float).unsqueeze(1).to(device)\n",
    "        b = params[:, 1].type(torch.float).unsqueeze(1).to(device)\n",
    "        return a*x + b\n",
    "    else:\n",
    "        return torch.zeros_like(params)\n",
    "\n",
    "def quadratic_function(params, x, device):\n",
    "    params = params.to(device)\n",
    "    x = x.to(device)\n",
    "    y = torch.zeros((params.size(0),x.shape[0])).to(device)\n",
    "    if params.size(1) > 2:\n",
    "        for n in range(len(params[0])):\n",
    "            y += (params[:, n].type(torch.float).unsqueeze(1).to(device))*x**(3-n)\n",
    "        return y\n",
    "    else:\n",
    "        return torch.zeros_like(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 1000\n",
    "sequence_length = 100\n",
    "batch_size = 50\n",
    "data_range = [-1, 1]\n",
    "num_funcs = 2\n",
    "\n",
    "x_values = torch.linspace(data_range[0], data_range[1], sequence_length)\n",
    "\n",
    "linear = Polynomial_func(x=x_values, range=data_range, degree=1, sample_size=sample_size, device=device)\n",
    "lin_full, _ = linear.generate()[0]\n",
    "\n",
    "quad = Polynomial_func(x=x_values, range=data_range, degree=2, sample_size=sample_size, device=device)\n",
    "quad_full, _ = quad.generate()[0]\n",
    "\n",
    "all_data = DataLoader(torch.vstack([quad_full, lin_full]), batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_loss(output, target, x):\n",
    "    x = x.clone().detach().requires_grad_(True)\n",
    "    target = target.clone().detach().requires_grad_(True)\n",
    "    derivative_true = torch.autograd.grad(outputs=target, inputs=x, grad_outputs=torch.ones_like(target), allow_unused=True)[0]\n",
    "    if derivative_true is None:\n",
    "        derivative_true = torch.zeros_like(output)\n",
    "    derivative_pred = (torch.roll(output, shifts=-1, dims=0) - torch.roll(output, shifts=1, dims=0)) / (2 * 1e-8)\n",
    "    mse_function = torch.mean(torch.abs(target - output)**3)\n",
    "    mse_derivative = torch.mean(torch.abs(derivative_pred - derivative_true)**3)\n",
    "    return mse_function + mse_derivative\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Multi_Func(nn.Module):\n",
    "    def __init__(self, functions, x_data, input_channels, transformer, device):\n",
    "        super().__init__()\n",
    "        self.device = device\n",
    "        self.functions = functions\n",
    "        self.x_data = x_data\n",
    "        self.input_channels = input_channels\n",
    "        self.params = sum(self.functions[1])\n",
    "        self.transformer = transformer\n",
    "\n",
    "    def forward(self, x, n=-1):\n",
    "        target = x.squeeze(dim=2)\n",
    "        print(f\"og x: {x.shape}\")\n",
    "        x = torch.swapaxes(x, 1, 2)\n",
    "        #print(f\"encoder in: {x.shape}\")\n",
    "        #encoder_out, _, _, _ = self.transformer.enc(x)\n",
    "        #print(f\"encoder out: {encoder_out.shape}\")\n",
    "        #encoder_out = torch.swapaxes(encoder_out, 0, 1)\n",
    "        #encoder_out = encoder_out.unsqueeze(1)\n",
    "        print(f\"transformer in: {x.shape}\")\n",
    "        embedding, _, _, _ = self.transformer(x)\n",
    "        print(f\"transforemr out: {x.shape}\")\n",
    "\n",
    "        print(f\"target: {target.shape}\")\n",
    "\n",
    "        start_index = 0\n",
    "        losses = []\n",
    "        outputs = []\n",
    "        \n",
    "        for f in range(len(self.functions[0])):\n",
    "            output = self.functions[0][f](\n",
    "                embedding[:, start_index:start_index+self.functions[1][f]], \n",
    "                self.x_data, \n",
    "                device=self.device\n",
    "            ).to(device)\n",
    "            outputs.append(output)\n",
    "            loss = new_loss(output, target, x)\n",
    "            losses.append(loss)\n",
    "            start_index += self.functions[1][f]\n",
    "\n",
    "        best_index = torch.argmin(torch.tensor(losses))\n",
    "        best_loss, best_out = losses[best_index], outputs[best_index]\n",
    "\n",
    "        return best_out, best_loss, outputs, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'num_heads = 2\\nembedding_size = 500\\n\\nif embedding_size % num_heads != 0:\\n    embedding_size = (embedding_size // num_heads + 1) * num_heads\\n\\nencoder = Encoder(\\n    input_channel=1, \\n    sequence_length=sequence_length,\\n    embedding_size=embedding_size,\\n    num_heads=num_heads\\n).to(device)\\n\\ndecoder = Decoder(\\n    input_channel=1, \\n    sequence_length=sequence_length,\\n    embedding_size=embedding_size,\\n    num_heads=num_heads\\n).to(device)\\n\\ntransformer = VAE(enc=encoder, dec=decoder, embedding_size=embedding_size).to(device)'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''num_heads = 2\n",
    "embedding_size = 500\n",
    "\n",
    "if embedding_size % num_heads != 0:\n",
    "    embedding_size = (embedding_size // num_heads + 1) * num_heads\n",
    "\n",
    "encoder = Encoder(\n",
    "    input_channel=1, \n",
    "    sequence_length=sequence_length,\n",
    "    embedding_size=embedding_size,\n",
    "    num_heads=num_heads\n",
    ").to(device)\n",
    "\n",
    "decoder = Decoder(\n",
    "    input_channel=1, \n",
    "    sequence_length=sequence_length,\n",
    "    embedding_size=embedding_size,\n",
    "    num_heads=num_heads\n",
    ").to(device)\n",
    "\n",
    "transformer = VAE(enc=encoder, dec=decoder, embedding_size=embedding_size).to(device)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "                sequence_length_encoder= 96, \n",
    "                sequence_length_decoder = 12,\n",
    "                input_channel=2, \n",
    "                embedding_size = 16, \n",
    "                cov1d_size=128,\n",
    "                num_heads = 4,\n",
    "                drop_out = 0.1,\n",
    "                learning_rate = 3e-5,\n",
    "                num_vae = 1,\n",
    "                fix_channel = False,\n",
    "                set_topK = True,\n",
    "                topk = 2,\n",
    "                channel_list = None\n",
    "                ):\n",
    "    \n",
    "    encoder = Encoder(sequence_length=sequence_length_encoder, \n",
    "                      input_channel=input_channel, \n",
    "                      embedding_size = embedding_size, \n",
    "                      cov1d_size=cov1d_size,\n",
    "                      num_heads = num_heads,\n",
    "                      drop_out = drop_out\n",
    "                        ).to(device)\n",
    "    \n",
    "    decoder = Decoder(sequence_length=sequence_length_decoder, \n",
    "                      input_channel=input_channel, \n",
    "                      embedding_size = embedding_size, \n",
    "                      cov1d_size=cov1d_size,\n",
    "                      num_heads = num_heads,\n",
    "                      drop_out = drop_out\n",
    "                     ).to(device)\n",
    "    \n",
    "    vae = VAE(encoder,\n",
    "              decoder,\n",
    "              embedding_size = embedding_size,\n",
    "              num_vae = num_vae,\n",
    "              fix_channel = fix_channel,\n",
    "              set_topK = set_topK,\n",
    "              topk = topk,\n",
    "              channel_list = channel_list).to(device)\n",
    "    \n",
    "    optimizer = optim.Adam(vae.parameters(), lr=learning_rate)\n",
    "    \n",
    "    return vae, encoder, decoder, optimizer\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer, encoder, decoder, optimizer = build_model(\n",
    "    sequence_length_encoder=sequence_length,\n",
    "    sequence_length_decoder=5,\n",
    "    input_channel=1,\n",
    "    embedding_size=16,\n",
    "    cov1d_size=128,\n",
    "    num_heads=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "og x: torch.Size([50, 100, 1])\n",
      "transformer in: torch.Size([50, 1, 100])\n",
      "transforemr out: torch.Size([50, 1, 100])\n",
      "target: torch.Size([50, 100])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (100) must match the size of tensor b (40) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[129], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m x \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      7\u001b[0m target_batch \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m----> 8\u001b[0m output, best_loss, outputs, losses \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_func(output,target_batch)\n\u001b[1;32m     11\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/miniconda3/envs/multifunc/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/multifunc/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[120], line 37\u001b[0m, in \u001b[0;36mMulti_Func.forward\u001b[0;34m(self, x, n)\u001b[0m\n\u001b[1;32m     31\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunctions[\u001b[38;5;241m0\u001b[39m][f](\n\u001b[1;32m     32\u001b[0m     embedding[:, start_index:start_index\u001b[38;5;241m+\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunctions[\u001b[38;5;241m1\u001b[39m][f]], \n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx_data, \n\u001b[1;32m     34\u001b[0m     device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\n\u001b[1;32m     35\u001b[0m )\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     36\u001b[0m outputs\u001b[38;5;241m.\u001b[39mappend(output)\n\u001b[0;32m---> 37\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mnew_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m losses\u001b[38;5;241m.\u001b[39mappend(loss)\n\u001b[1;32m     39\u001b[0m start_index \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunctions[\u001b[38;5;241m1\u001b[39m][f]\n",
      "Cell \u001b[0;32mIn[73], line 8\u001b[0m, in \u001b[0;36mnew_loss\u001b[0;34m(output, target, x)\u001b[0m\n\u001b[1;32m      6\u001b[0m     derivative_true \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros_like(output)\n\u001b[1;32m      7\u001b[0m derivative_pred \u001b[38;5;241m=\u001b[39m (torch\u001b[38;5;241m.\u001b[39mroll(output, shifts\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, dims\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m-\u001b[39m torch\u001b[38;5;241m.\u001b[39mroll(output, shifts\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, dims\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)) \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1e-8\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m mse_function \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(torch\u001b[38;5;241m.\u001b[39mabs(\u001b[43mtarget\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m      9\u001b[0m mse_derivative \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(torch\u001b[38;5;241m.\u001b[39mabs(derivative_pred \u001b[38;5;241m-\u001b[39m derivative_true)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m mse_function \u001b[38;5;241m+\u001b[39m mse_derivative\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (100) must match the size of tensor b (40) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    "model = Multi_Func(functions=[[linear_function, quadratic_function],[2,3]], x_data=x_values, input_channels=1, transformer=transformer, device=device).to(device)\n",
    "loss_func = nn.MSELoss()\n",
    "scheduler = StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "for epoch in range(5):\n",
    "    for batch in all_data:\n",
    "        x = batch.to(device)\n",
    "        target_batch = batch.squeeze(2).to(device)\n",
    "        output, best_loss, outputs, losses = model(x)\n",
    "        \n",
    "        loss = loss_func(output,target_batch)\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        optimizer.step()\n",
    "        \n",
    "        print(f'Epoch {epoch}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 1\n",
    "for epoch in range(epochs):\n",
    "    start_time = time.time()\n",
    "    train_loss = 0.0\n",
    "    total_num = 0\n",
    "    model.train()\n",
    "    function_losses = {i: [] for i in range(len(model.functions[0]))}\n",
    "    \n",
    "    for train_batch in all_data:\n",
    "        train_batch = train_batch.to(device)\n",
    "        target_batch = train_batch.squeeze(2).to(device)\n",
    "        optimizer.zero_grad()\n",
    "        best_out,best_loss,outputs,losses = model(train_batch)\n",
    "        for i, loss in enumerate(losses):\n",
    "            function_losses[i].append(loss.item())\n",
    "        loss = loss_func(best_out,target_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * best_out.shape[0]\n",
    "        total_num += best_out.shape[0]\n",
    "    scheduler.step()\n",
    "    train_loss /= total_num\n",
    "    print(f\"epoch : {epoch}/{epochs}, loss = {train_loss:.8f}\")\n",
    "    print(f\"--- {time.time() - start_time} seconds ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "                sequence_length_encoder= 96, \n",
    "                sequence_length_decoder = 12,\n",
    "                input_channel=2, \n",
    "                embedding_size = 16, \n",
    "                cov1d_size=128,\n",
    "                num_heads = 4,\n",
    "                drop_out = 0.1,\n",
    "                learning_rate = 3e-5,\n",
    "                num_vae = 1,\n",
    "                fix_channel = False,\n",
    "                set_topK = True,\n",
    "                topk = 2,\n",
    "                channel_list = None\n",
    "                ):\n",
    "    \n",
    "    encoder = Encoder(sequence_length=sequence_length_encoder, \n",
    "                      input_channel=input_channel, \n",
    "                      embedding_size = embedding_size, \n",
    "                      cov1d_size=cov1d_size,\n",
    "                      num_heads = num_heads,\n",
    "                      drop_out = drop_out\n",
    "                        ).to(device)\n",
    "    \n",
    "    decoder = Decoder(sequence_length=sequence_length_decoder, \n",
    "                      input_channel=input_channel, \n",
    "                      embedding_size = embedding_size, \n",
    "                      cov1d_size=cov1d_size,\n",
    "                      num_heads = num_heads,\n",
    "                      drop_out = drop_out\n",
    "                     ).to(device)\n",
    "    \n",
    "    vae = VAE(encoder,\n",
    "              decoder,\n",
    "              embedding_size = embedding_size,\n",
    "              num_vae = num_vae,\n",
    "              fix_channel = fix_channel,\n",
    "              set_topK = set_topK,\n",
    "              topk = topk,\n",
    "              channel_list = channel_list).to(device)\n",
    "    \n",
    "    optimizer = optim.Adam(vae.parameters(), lr=learning_rate)\n",
    "    \n",
    "    return vae, encoder, decoder, optimizer\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae, encoder, decoder, optimizer = build_model(\n",
    "    device=device,\n",
    "    input_channel=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [128, 1, 3], expected input[10000, 1000, 1] to have 1 channels, but got 1000 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mvae\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlin_full\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/multifunc/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/multifunc/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[6], line 71\u001b[0m, in \u001b[0;36mVAE.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \n\u001b[1;32m     68\u001b[0m             x,\n\u001b[1;32m     69\u001b[0m            ):\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;66;03m# encode\u001b[39;00m\n\u001b[0;32m---> 71\u001b[0m     encoder_out,enc_trans_1,enc_trans_2,enc_trans_3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;66;03m# variational layer\u001b[39;00m\n\u001b[1;32m     74\u001b[0m     mn_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmn(encoder_out)\n",
      "File \u001b[0;32m~/miniconda3/envs/multifunc/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/multifunc/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[4], line 51\u001b[0m, in \u001b[0;36mEncoder.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 51\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcov1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m     enc_trans_1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer_1(out)\n\u001b[1;32m     55\u001b[0m     enc_trans_2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer_2(enc_trans_1)\n",
      "File \u001b[0;32m~/miniconda3/envs/multifunc/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/multifunc/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/multifunc/lib/python3.11/site-packages/torch/nn/modules/conv.py:308\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 308\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/multifunc/lib/python3.11/site-packages/torch/nn/modules/conv.py:304\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    302\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    303\u001b[0m                     _single(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 304\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [128, 1, 3], expected input[10000, 1000, 1] to have 1 channels, but got 1000 channels instead"
     ]
    }
   ],
   "source": [
    "vae(lin_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [128, 2, 3], expected input[10000, 1, 1000] to have 2 channels, but got 1 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m VAE(model1,model2,fix_channel\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, channel_list\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# out, enc_trans_1, enc_trans_2, enc_trans_3 = model1(input_data)\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m predicted, embedding,mn_,var_\u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlin_full\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/multifunc/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/multifunc/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[6], line 71\u001b[0m, in \u001b[0;36mVAE.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \n\u001b[1;32m     68\u001b[0m             x,\n\u001b[1;32m     69\u001b[0m            ):\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;66;03m# encode\u001b[39;00m\n\u001b[0;32m---> 71\u001b[0m     encoder_out,enc_trans_1,enc_trans_2,enc_trans_3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;66;03m# variational layer\u001b[39;00m\n\u001b[1;32m     74\u001b[0m     mn_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmn(encoder_out)\n",
      "File \u001b[0;32m~/miniconda3/envs/multifunc/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/multifunc/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[4], line 51\u001b[0m, in \u001b[0;36mEncoder.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m---> 51\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcov1d\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m     enc_trans_1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer_1(out)\n\u001b[1;32m     55\u001b[0m     enc_trans_2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransformer_2(enc_trans_1)\n",
      "File \u001b[0;32m~/miniconda3/envs/multifunc/lib/python3.11/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/multifunc/lib/python3.11/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/multifunc/lib/python3.11/site-packages/torch/nn/modules/conv.py:308\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 308\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/multifunc/lib/python3.11/site-packages/torch/nn/modules/conv.py:304\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[1;32m    302\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[1;32m    303\u001b[0m                     _single(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[0;32m--> 304\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [128, 2, 3], expected input[10000, 1, 1000] to have 2 channels, but got 1 channels instead"
     ]
    }
   ],
   "source": [
    "model1 = Encoder()\n",
    "model2 = Decoder()\n",
    "\n",
    "model = VAE(model1,model2,fix_channel=False, channel_list=[1])\n",
    "# out, enc_trans_1, enc_trans_2, enc_trans_3 = model1(input_data)\n",
    "\n",
    "predicted, embedding,mn_,var_= model(lin_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "                sequence_length_encoder= 96, \n",
    "                sequence_length_decoder = 12,\n",
    "                input_channel=2, \n",
    "                embedding_size = 16, \n",
    "                cov1d_size=128,\n",
    "                num_heads = 4,\n",
    "                drop_out = 0.1,\n",
    "                learning_rate = 3e-5,\n",
    "                num_vae = 1,\n",
    "                fix_channel = False,\n",
    "                set_topK = True,\n",
    "                topk = 2,\n",
    "                channel_list = None\n",
    "                ):\n",
    "    \n",
    "    encoder = Encoder(sequence_length=sequence_length_encoder, \n",
    "                      input_channel=input_channel, \n",
    "                      embedding_size = embedding_size, \n",
    "                      cov1d_size=cov1d_size,\n",
    "                      num_heads = num_heads,\n",
    "                      drop_out = drop_out\n",
    "                        ).to(device)\n",
    "    \n",
    "    decoder = Decoder(sequence_length=sequence_length_decoder, \n",
    "                      input_channel=input_channel, \n",
    "                      embedding_size = embedding_size, \n",
    "                      cov1d_size=cov1d_size,\n",
    "                      num_heads = num_heads,\n",
    "                      drop_out = drop_out\n",
    "                     ).to(device)\n",
    "    \n",
    "    vae = VAE(encoder,\n",
    "              decoder,\n",
    "              embedding_size = embedding_size,\n",
    "              num_vae = num_vae,\n",
    "              fix_channel = fix_channel,\n",
    "              set_topK = set_topK,\n",
    "              topk = topk,\n",
    "              channel_list = channel_list).to(device)\n",
    "    \n",
    "    optimizer = optim.Adam(vae.parameters(), lr=learning_rate)\n",
    "    \n",
    "    return vae, encoder, decoder, optimizer\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "multifunc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
